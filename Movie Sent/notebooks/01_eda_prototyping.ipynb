{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MovieSent â€“ EDA & Prototyping\n",
        "\n",
        "This notebook explores the dataset, demonstrates preprocessing, and prototypes features for both models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.utils.text_preprocess import load_reviews_csv, prepare_dataset, preprocess_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "DATA_PATH = os.path.join(os.getcwd(), 'IMDB Dataset.csv')\n",
        "df_raw = load_reviews_csv(DATA_PATH)\n",
        "df = prepare_dataset(df_raw)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic info\n",
        "print(df.shape)\n",
        "df.isna().sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Class balance\n",
        "sns.countplot(x=df['label'])\n",
        "plt.title('Label Distribution (after mapping)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing demo\n",
        "sample = df['review'].iloc[0]\n",
        "print('Original:', sample[:400])\n",
        "print('\\nProcessed:', preprocess_text(sample)[:400])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF baseline quick check\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "bin_df = df[df['label'].isin([0,1])]\n",
        "X = bin_df['clean_review'].values\n",
        "y = bin_df['label'].astype(int).values\n",
        "Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
        "vec = TfidfVectorizer(ngram_range=(1,2), max_features=50000, min_df=2)\n",
        "Xtrv = vec.fit_transform(Xtr)\n",
        "Xtev = vec.transform(Xte)\n",
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(Xtrv, ytr)\n",
        "print(classification_report(yte, clf.predict(Xtev)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenizer setup demo (LSTM)\n",
        "from tensorflow import keras\n",
        "MAX_VOCAB = 20000\n",
        "MAX_LEN = 200\n",
        "texts = bin_df['clean_review'].astype(str).tolist()\n",
        "\n",
        "tok = keras.preprocessing.text.Tokenizer(num_words=MAX_VOCAB, oov_token='<OOV>')\n",
        "tok.fit_on_texts(texts)\n",
        "seq = tok.texts_to_sequences(texts[:5])\n",
        "pad = keras.preprocessing.sequence.pad_sequences(seq, maxlen=MAX_LEN)\n",
        "pad.shape\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
